{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pyautogui\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "video_name = 'test_video.mp4'\n",
    "tenhon_name = 'tenhon.png'\n",
    "tenhon_name2 = 'tenhon2.png'\n",
    "global rc\n",
    "rc = 200\n",
    "global red\n",
    "red = (0,0,255)\n",
    "global green\n",
    "green = (0,255,0)\n",
    "global blue\n",
    "blue = (255,0,0)\n",
    "global marking\n",
    "marking = False\n",
    "showing = False\n",
    "zsize = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_range(str):\n",
    "    \n",
    "    if str == \"blue\":\n",
    "        l = np.array([rc,0,0])\n",
    "        \n",
    "    elif str == \"green\":\n",
    "        l = np.array([0, rc, 0])\n",
    "    elif str == \"red\":\n",
    "        l = np.array([0, 0, rc])\n",
    "\n",
    "    u = np.array([255,255,255])\n",
    "\n",
    "    return l, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    cv.imshow(\"title\", img)\n",
    "        \n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        cv.destroyAllWindows()\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    cv.imshow(\"title\", img)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_fliter(img, string):\n",
    "    l, u = color_range(string)\n",
    "    mask = cv.inRange(img, l, u)\n",
    "    img = cv.bitwise_or(img, img, mask=mask)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(img):\n",
    "\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    im_thresh = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 21, 0)\n",
    "\n",
    "    return cv.findContours(im_thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img, x, y, w, h):\n",
    "    cv.rectangle(img, (x,y), (x+w, y+h), green, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(img, x, y, string):\n",
    "    cv.putText(img, string, (x, y), cv.FONT_HERSHEY_PLAIN, 1, red, 1, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwhile True:\\n\\n    screenshot = pyautogui.screenshot()\\n    screenshot = np.array(screenshot)\\n    screenshot = cv.cvtColor(screenshot, cv.COLOR_RGB2BGR)\\n    cv.imshow('', screenshot)\\n\\n    if cv.waitKey(1) == ord('q'):\\n        cv.destroyAllWindows()\\n        break\\n\\nprint('Done')\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "while True:\n",
    "\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    screenshot = np.array(screenshot)\n",
    "    screenshot = cv.cvtColor(screenshot, cv.COLOR_RGB2BGR)\n",
    "    cv.imshow('', screenshot)\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        cv.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "print('Done')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(Callback):\n",
    "\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None): \n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        current_loss = logs.get(\"loss\")\n",
    "        current_accuracy = logs.get(\"accuracy\")\n",
    "        if np.less(current_loss, self.best) :\n",
    "            self.best = current_loss\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights() \n",
    "\n",
    "            if current_loss < 1e-4 and current_accuracy == 1.0:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = os.listdir(path+\"/orignal_data\")\n",
    "\n",
    "img_name = [i for i in img_name if \"png\" in i and \"tenhon\" in i]\n",
    "\n",
    "sol_dict = dict()\n",
    "\n",
    "f = open(path+\"/orignal_data/tenhon_sol.txt\", 'r')\n",
    "\n",
    "for name, line in zip(img_name, f.readlines()):\n",
    "    line = line.replace(\"\\n\",\"\").split(\" \")\n",
    "    sol_dict[name] = line\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = path + \"/train_data/\"\n",
    "\n",
    "for file_name in sol_dict.keys():\n",
    "\n",
    "    img = cv.imread(\"./orignal_data/\" + file_name)\n",
    "    \n",
    "    mask_img = color_fliter(img, \"blue\")\n",
    "    \n",
    "    contour, hierarchy = find_contours(mask_img)\n",
    "\n",
    "    contour_list = list()\n",
    "\n",
    "    for pos in range(len(contour)):\n",
    "        \n",
    "        x, y, w, h = cv.boundingRect(contour[pos])\n",
    "\n",
    "        if ((w > 20 and w < 100 and h > 40 and h < 150) or (h > 20 and h < 100 and w > 40 and w < 150)):\n",
    "\n",
    "            contour_list.append([x,y,w,h,contour[pos]])\n",
    "\n",
    "            if marking:\n",
    "                draw_rectangle(img, x, y, w, h)\n",
    "            \n",
    "        if showing:\n",
    "            show(img)\n",
    "\n",
    "    contour_list.sort(key=lambda x : (x[1], x[0]))\n",
    "\n",
    "    for (x,y,w,h,_), string in zip(contour_list, sol_dict[file_name]):\n",
    "        \n",
    "        if string in os.listdir(train_path):\n",
    "            continue\n",
    "        else:\n",
    "            pe = train_path + \"/\" + string\n",
    "            os.mkdir(pe)\n",
    "\n",
    "            part = img[y:y+h, x:x+w]\n",
    "\n",
    "            cv.imwrite(pe+\"/\"+string + \"ori\" + \".png\", part)\n",
    "\n",
    "            count = 1\n",
    "\n",
    "            for _ in range(0,4):\n",
    "                \n",
    "                for xn in range(-4, 4, 2):\n",
    "                    for yn in range(-6, 6, 2):\n",
    "\n",
    "                        if len(string) > 2:\n",
    "\n",
    "                            if string[2] == \"r\" and (abs(xn) > 4 or abs(yn) > 6):\n",
    "                                continue\n",
    "\n",
    "                        if x > y:\n",
    "                            temp = yn\n",
    "                            yn = xn\n",
    "                            xn = temp\n",
    "\n",
    "                        w = part.shape[1]\n",
    "                        h = part.shape[0]\n",
    "                        \n",
    "                        p = part[np.where(yn > 0, yn, 0):np.where(yn > 0, h, h+yn), np.where(xn > 0, xn, 0):np.where(xn > 0, w, w+xn)]\n",
    "\n",
    "                        for size in range(0,50,10):\n",
    "                            ps = cv.resize(p, (int(p.shape[1] * ((100-size)/100)), int(p.shape[0] * ((100-size)/100))))\n",
    "\n",
    "                            cv.imwrite(pe+\"/\"+string + str(count) + \".png\", ps)\n",
    "\n",
    "                            count+= 1\n",
    "\n",
    "                part = cv.rotate(part, cv.ROTATE_90_CLOCKWISE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = path + \"/train_data/\"\n",
    "\n",
    "if \"ztr\" not in os.listdir(train_path):\n",
    "    os.mkdir(train_path + \"/ztr\")\n",
    "\n",
    "img = cv.imread(path + \"orignal_data/dumn1.png\")\n",
    "\n",
    "mask_img = color_fliter(img, \"blue\")\n",
    "\n",
    "contour, hierarchy = find_contours(mask_img)\n",
    "\n",
    "contour_list = list()\n",
    "\n",
    "for pos in range(len(contour)):\n",
    "        \n",
    "        x, y, w, h = cv.boundingRect(contour[pos])\n",
    "\n",
    "        if ((w > 20 and w < 100 and h > 40 and h < 150) or (h > 20 and h < 100 and w > 40 and w < 150)):\n",
    "\n",
    "            contour_list.append([x,y,w,h,contour[pos]])\n",
    "\n",
    "\n",
    "for count, (x,y,w,h,_) in enumerate(contour_list):\n",
    "    \n",
    "    pe = train_path + \"/\" + \"ztr\"\n",
    "    part = img[y:y+h, x:x+w]\n",
    "    cv.imwrite(pe+\"/\"+str(count)+\".png\", part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = path + \"/train_data/\"\n",
    "\n",
    "img = cv.imread(path + \"orignal_data/dumn2.png\")\n",
    "\n",
    "mask_img = color_fliter(img, \"blue\")\n",
    "\n",
    "contour, hierarchy = find_contours(mask_img)\n",
    "\n",
    "contour_list = list()\n",
    "\n",
    "count = 0\n",
    "\n",
    "xy_list = list()\n",
    "\n",
    "for pos in range(len(contour)):\n",
    "    \n",
    "    x, y, w, h = cv.boundingRect(contour[pos])\n",
    "\n",
    "    if ((w > 20 and w < 100 and h > 40 and h < 150) or (h > 20 and h < 100 and w > 40 and w < 150)):\n",
    "\n",
    "        # contour_list.append(contour[pos])\n",
    "\n",
    "        part = img[y+int(h*0.1):y+int(h*0.9), x+int(w*0.1):x+int(w*0.9)]\n",
    "\n",
    "        part = cv.resize(part, (zsize, zsize))\n",
    "\n",
    "        contour_list.append(part)\n",
    "        xy_list.append([x,y,w,h])\n",
    "\n",
    "        # if marking:\n",
    "\n",
    "        #     draw_rectangle(frame, x,y,w,h)\n",
    "\n",
    "if len(contour_list) > 0:\n",
    "\n",
    "    k = im_model.predict(np.array(contour_list), verbose=0)\n",
    "\n",
    "    k = np.argmax(k, axis=1)\n",
    "\n",
    "    for (x,y,w,h),label in zip(xy_list,k):\n",
    "\n",
    "        cv.rectangle(img, (x,y), (x+w, y+h), green, 3)\n",
    "        cv.putText(img, label_dict[label], (x, y), cv.FONT_HERSHEY_PLAIN, 2, red, 1, cv.LINE_AA)\n",
    "\n",
    "cv.imshow(\"title\", img)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "str_dict = \"\"\"\n",
    "1s = 0\n",
    "2s = 1\n",
    "3s = 2\n",
    "4s = 3\n",
    "5s = 4\n",
    "6s = 5\n",
    "7s = 6\n",
    "8s = 7\n",
    "9s = 8\n",
    "5sr = 9\n",
    "1m = 10\n",
    "2m = 11\n",
    "3m = 12\n",
    "4m = 13\n",
    "5m = 14\n",
    "6m = 15\n",
    "7m = 16\n",
    "8m = 17\n",
    "9m = 18\n",
    "5mr = 19\n",
    "1p = 20\n",
    "2p = 21\n",
    "3p = 22\n",
    "4p = 23\n",
    "5p = 24\n",
    "6p = 25\n",
    "7p = 26\n",
    "8p = 27\n",
    "9p = 28\n",
    "5pr = 29\n",
    "ew = 30\n",
    "sw = 31\n",
    "ww = 32\n",
    "nw = 33\n",
    "wd = 34\n",
    "gd = 35\n",
    "rd = 36\n",
    "ztr = 37\n",
    "\"\"\"\n",
    "\n",
    "str_dict = \"{\" + str_dict.replace(\" \",\"\").replace(\"=\",\"\\\":\").replace(\"\\n\", \",\\\"\")[1:-2] + \"}\"\n",
    "\n",
    "str_dict = eval(str_dict)\n",
    "\n",
    "if \"train_data\" not in os.listdir(path):\n",
    "    os.mkdir(path+\"/train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = path+\"/\"+\"train_data\"\n",
    "\n",
    "file_names = os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, BatchNormalization, Input, Flatten, Conv1D, MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(zsize):\n",
    "    input_layer = Input((zsize,zsize,3))\n",
    "    conv_layer = Conv2D(16, (2,2), activation='relu')(input_layer)\n",
    "    max_layer = MaxPool2D((2,2))(conv_layer)\n",
    "    # bn_layer = BatchNormalization()(max_layer)\n",
    "    conv_layer = Conv2D(32, (2,2), activation='relu')(max_layer)\n",
    "    max_layer = MaxPool2D((2,2))(conv_layer)\n",
    "    # bn_layer = BatchNormalization()(max_layer)\n",
    "    conv_layer = Conv2D(64, (2,2),  activation='relu')(max_layer)\n",
    "    max_layer = MaxPool2D((2,2))(conv_layer)\n",
    "    bn_layer = BatchNormalization()(max_layer)\n",
    "    conv_layer = Conv2D(128, (2,2),  activation='relu')(bn_layer)\n",
    "    max_layer = MaxPool2D((2,2))(conv_layer)\n",
    "    # bn_layer = BatchNormalization()(max_layer)\n",
    "    # conv_layer = Conv2D(128, (2,2),  activation='relu')(bn_layer)\n",
    "    # max_layer = MaxPool2D((2,2))(conv_layer)\n",
    "    flatten_layer = Flatten()(max_layer)\n",
    "    fc_layer = Dense(76, activation='relu')(flatten_layer)\n",
    "    fc_layer = Dense(38, activation='softmax')(fc_layer)\n",
    "\n",
    "    model = Model(input_layer, fc_layer)\n",
    "    model.compile(optimizer=Adam(1e-3), loss='sparse_categorical_crossentropy', metrics=\"accuracy\")\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_nn_model(zsize):\n",
    "    input_layer = Input((zsize,zsize))\n",
    "    conv_layer = Conv1D(16, 2, activation='relu')(input_layer)\n",
    "    max_layer = MaxPool1D(2)(conv_layer)\n",
    "    bn_layer = BatchNormalization()(max_layer)\n",
    "    conv_layer = Conv1D(32, 2, activation='relu')(bn_layer)\n",
    "    max_layer = MaxPool1D(2)(conv_layer)\n",
    "    bn_layer = BatchNormalization()(max_layer)\n",
    "    conv_layer = Conv1D(64, 2, activation='relu')(bn_layer)\n",
    "    max_layer = MaxPool1D(2)(conv_layer)\n",
    "    bn_layer = BatchNormalization()(max_layer)\n",
    "    conv_layer = Conv1D(64, 2, activation='relu')(bn_layer)\n",
    "    max_layer = MaxPool1D(2)(conv_layer)\n",
    "    # bn_layer = BatchNormalization()(max_layer)\n",
    "    flatten_layer = Flatten()(max_layer)\n",
    "    fc_layer = Dense(38, activation='relu')(flatten_layer)\n",
    "    # bn_layer = BatchNormalization()(fc_layer)\n",
    "    fc_layer = Dense(38, activation='softmax')(fc_layer)\n",
    "    \n",
    "    model = Model(input_layer, fc_layer)\n",
    "    model.compile(optimizer=Adam(1e-3), loss='sparse_categorical_crossentropy', metrics=\"accuracy\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 89, 89, 16)        208       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 44, 44, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 43, 43, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 21, 21, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 10, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 9, 9, 128)         32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 76)                155724    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                2926      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,346\n",
      "Trainable params: 202,218\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "im_model = nn_model(zsize)\n",
    "im_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = list()\n",
    "label_list = list()\n",
    "\n",
    "\n",
    "for name in file_names:\n",
    "\n",
    "    if \".txt\" in name:\n",
    "        continue\n",
    "\n",
    "    sub_list = os.listdir(train_path + \"/\" + name)\n",
    "    \n",
    "    for sub in sub_list:\n",
    "        p = cv.imread(train_path + \"/\" + name + \"/\" + sub)\n",
    "        p = cv.resize(p, (zsize,zsize))\n",
    "\n",
    "        image_list.append(p)\n",
    "        label_list.append(str_dict[name])\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_data = list()\n",
    "noise_label = list()\n",
    "\n",
    "for _ in range(77500):\n",
    "\n",
    "    n = np.random.randint(0,255,(zsize,zsize,3))\n",
    "    # n = np.where(n > 125, 255, 0)\n",
    "\n",
    "    noise_data.append(n)\n",
    "    noise_label.append(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "68/68 [==============================] - 29s 419ms/step - loss: 0.9038 - accuracy: 0.7862\n",
      "Epoch 2/300\n",
      "68/68 [==============================] - 29s 420ms/step - loss: 0.0166 - accuracy: 0.9998\n",
      "Epoch 3/300\n",
      "68/68 [==============================] - 28s 415ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 4/300\n",
      "68/68 [==============================] - 31s 459ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 5/300\n",
      "68/68 [==============================] - 33s 478ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 6/300\n",
      "68/68 [==============================] - 32s 478ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 7/300\n",
      "68/68 [==============================] - 33s 485ms/step - loss: 7.4765e-04 - accuracy: 1.0000\n",
      "Epoch 8/300\n",
      "68/68 [==============================] - 32s 476ms/step - loss: 5.7275e-04 - accuracy: 1.0000\n",
      "Epoch 9/300\n",
      "68/68 [==============================] - 33s 489ms/step - loss: 4.5328e-04 - accuracy: 1.0000\n",
      "Epoch 10/300\n",
      "68/68 [==============================] - 33s 483ms/step - loss: 3.7084e-04 - accuracy: 1.0000\n",
      "Epoch 11/300\n",
      "68/68 [==============================] - 33s 487ms/step - loss: 3.0199e-04 - accuracy: 1.0000\n",
      "Epoch 12/300\n",
      "68/68 [==============================] - 33s 482ms/step - loss: 2.5637e-04 - accuracy: 1.0000\n",
      "Epoch 13/300\n",
      "68/68 [==============================] - 33s 484ms/step - loss: 2.1794e-04 - accuracy: 1.0000\n",
      "Epoch 14/300\n",
      "68/68 [==============================] - 33s 493ms/step - loss: 1.8619e-04 - accuracy: 1.0000\n",
      "Epoch 15/300\n",
      "68/68 [==============================] - 32s 476ms/step - loss: 1.6233e-04 - accuracy: 1.0000\n",
      "Epoch 16/300\n",
      "68/68 [==============================] - 32s 474ms/step - loss: 1.4313e-04 - accuracy: 1.0000\n",
      "Epoch 17/300\n",
      "68/68 [==============================] - 32s 472ms/step - loss: 1.2498e-04 - accuracy: 1.0000\n",
      "Epoch 18/300\n",
      "68/68 [==============================] - 34s 496ms/step - loss: 1.1121e-04 - accuracy: 1.0000\n",
      "Epoch 19/300\n",
      "68/68 [==============================] - 33s 479ms/step - loss: 9.7165e-05 - accuracy: 1.0000\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "im_model = nn_model(zsize)\n",
    "\n",
    "# im_model.compile(optimizer=Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=\"accuracy\")\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "\n",
    "    # im_model.fit(np.array(image_list + noise_data), np.array(label_list + noise_label), batch_size=1024, epochs=300, callbacks=[CustomCallback()])\n",
    "    # im_model = nn_model(zsize)\n",
    "    im_model.fit(np.array(image_list), np.array(label_list), batch_size=256, epochs=300, callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict((v,k) for k, v in str_dict.items())\n",
    "\n",
    "cap = cv.VideoCapture(path+video_name)\n",
    "\n",
    "while (cap.isOpened()):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    mask_img = color_fliter(frame, \"blue\")\n",
    "    \n",
    "    contour, hierarchy = find_contours(mask_img)\n",
    "\n",
    "    contour_list = list()\n",
    "\n",
    "    xy_list = list()\n",
    "\n",
    "    # img_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # img_gray = cv.Canny(img_gray, 220, 220)\n",
    "\n",
    "    # img_gray = np.where(img_gray > 200 , 255, img_gray)\n",
    "    \n",
    "    for pos in range(len(contour)):\n",
    "        \n",
    "        x, y, w, h = cv.boundingRect(contour[pos])\n",
    "\n",
    "        if ((w > 20 and w < 100 and h > 40 and h < 150) or (h > 20 and h < 100 and w > 40 and w < 150)):\n",
    "\n",
    "            # contour_list.append(contour[pos])\n",
    "\n",
    "            # part = img_gray[y+int(h*0.1):y+int(h*0.9), x+int(w*0.1):x+int(w*0.9)]\n",
    "            part = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # part = cv.Canny(part, 255,255)\n",
    "\n",
    "            part = cv.resize(part, (zsize, zsize))\n",
    "\n",
    "            contour_list.append(part)\n",
    "            xy_list.append([x,y,w,h])\n",
    "\n",
    "            # if marking:\n",
    "\n",
    "            #     draw_rectangle(frame, x,y,w,h)\n",
    "\n",
    "    if len(contour_list) > 0:\n",
    "\n",
    "        k = im_model.predict(np.array(contour_list), verbose=0)\n",
    "\n",
    "        k = np.argmax(k, axis=1)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for (x,y,w,h),label in zip(xy_list,k):\n",
    "\n",
    "            if label < 37:\n",
    "\n",
    "                cv.rectangle(frame, (x,y), (x+w, y+h), green, 3)\n",
    "                cv.putText(frame, label_dict[label], (x, y), cv.FONT_HERSHEY_PLAIN, 2, red, 1, cv.LINE_AA)\n",
    "\n",
    "    isBreak = show(frame)\n",
    "        \n",
    "    if isBreak:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "#read image\n",
    "img = cv2.imread(\"./train_data/1m/1m.png\")\n",
    "\n",
    "# change size of image\n",
    "width = int(img.shape[1])\n",
    "height = int(img.shape[0])\n",
    "dim = (width, height)\n",
    "\n",
    "min_color = int(np.max(img))\n",
    "min_color = (min_color, min_color, min_color)\n",
    "\n",
    "# img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "#2d to 3d (projection)  , and -> rotation point - center point (origin point)\n",
    "proj2dto3d = np.array([[1,0,-img.shape[1]],\n",
    "                      [0,1,-img.shape[0]],\n",
    "                      [0,0,0],\n",
    "                      [0,0,1]],np.float32)\n",
    "\n",
    "# 3d matrixs in  x ,y ,z \n",
    "\n",
    "'''\n",
    " you can remove any matrix if you dont want to rotate around it , so in our case \n",
    " we rotate around y axis only so any line ends with \" #0 \" we can remove it \n",
    " and the programe will run \n",
    "\n",
    "'''\n",
    "rx   = np.array([[1,0,0,0],\n",
    "                 [0,1,0,0],\n",
    "                 [0,0,1,0],\n",
    "                 [0,0,0,1]],np.float32)\n",
    "\n",
    "ry   = np.array([[1,0,0,0],\n",
    "                 [0,1,0,0],\n",
    "                 [0,0,1,0],\n",
    "                 [0,0,0,1]],np.float32)\n",
    "\n",
    "rz   = np.array([[1,0,0,0],\n",
    "                 [0,1,0,0],\n",
    "                 [0,0,1,0],\n",
    "                 [0,0,0,1]],np.float32)\n",
    "\n",
    "\n",
    "trans= np.array([[1,0,0,0],\n",
    "                 [0,1,0,0],\n",
    "                 [0,0,1,height+20],\n",
    "                 [0,0,0,1]],np.float32)\n",
    "\n",
    "\n",
    "\n",
    "proj3dto2d = np.array([ [width,0,img.shape[1],0],\n",
    "                        [0,height,img.shape[0],0],\n",
    "                        [0,0,1,0] ],np.float32)\n",
    "\n",
    "x = -40.0 #0\n",
    "y = 0.0\n",
    "z = 0.0 #0\n",
    "\n",
    "\n",
    "ax = float(x * (math.pi / 180.0)) #0\n",
    "ay = float(y * (math.pi / 180.0)) \n",
    "az = float(z * (math.pi / 180.0)) #0\n",
    "\n",
    "rx[1,1] = math.cos(ax) #0\n",
    "rx[1,2] = -math.sin(ax) #0\n",
    "rx[2,1] = math.sin(ax) #0\n",
    "rx[2,2] = math.cos(ax) #0\n",
    "\n",
    "ry[0,0] = math.cos(ay)\n",
    "ry[0,2] = -math.sin(ay)\n",
    "ry[2,0] = math.sin(ay)\n",
    "ry[2,2] = math.cos(ay)\n",
    "\n",
    "rz[0,0] = math.cos(az) #0\n",
    "rz[0,1] = -math.sin(az) #0\n",
    "rz[1,0] = math.sin(az) #0\n",
    "rz[1,1] = math.cos(az) #0\n",
    "\n",
    "r =rx.dot(ry).dot(rz) # if we remove the lines we put    r=ry\n",
    "final = proj3dto2d.dot(trans.dot(r.dot(proj2dto3d)))\n",
    "\n",
    "dst = cv2.warpPerspective(img, final,(img.shape[1],img.shape[0]),None,cv2.INTER_LINEAR\n",
    "                            ,cv2.BORDER_CONSTANT,min_color)\n",
    "\n",
    "\n",
    "cv2.imshow(\"dst\",dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./dumn2.PNG\")\n",
    "\n",
    "mask_img = color_fliter(img, \"blue\")\n",
    "    \n",
    "contour, hierarchy = find_contours(mask_img)\n",
    "\n",
    "contour_list = list()\n",
    "\n",
    "xy_list = list()\n",
    "\n",
    "# img_gray = cv.cvtColor(mask_img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# img_gray = cv.Canny(img_gray, 255, 255)\n",
    "\n",
    "# img_gray = np.where(img_gray > 200 , 255, img_gray)\n",
    "\n",
    "for pos in range(len(contour)):\n",
    "    \n",
    "    x, y, w, h = cv.boundingRect(contour[pos])\n",
    "\n",
    "    if (w > 20 and w < 100 and h > 40 and h < 150) or (h > 20 and h < 100 and w > 40 and w < 150):\n",
    "\n",
    "        # contour_list.append(contour[pos])\n",
    "\n",
    "        # part = img_gray[y+int(h*0.1):y+int(h*0.9), x+int(w*0.1):x+int(w*0.9)]\n",
    "        part = img[y:y+h, x:x+w]\n",
    "\n",
    "        # part = cv.Canny(part, 255, 255)\n",
    "\n",
    "        part = cv.resize(part, (zsize, zsize))\n",
    "\n",
    "        contour_list.append(part)\n",
    "        xy_list.append([x,y,w,h])\n",
    "\n",
    "        # show_img(part)\n",
    "\n",
    "k = im_model.predict(np.array(contour_list), verbose=0)\n",
    "\n",
    "k = np.argmax(k, axis=1)\n",
    "\n",
    "\n",
    "# img_gray = cv.cvtColor(img_gray, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "for ((x,y,w,h), label) in zip(xy_list,k):\n",
    "\n",
    "    cv.rectangle(img, (x,y), (x+w, y+h), green, 3)\n",
    "    cv.putText(img, label_dict[label], (x, y), cv.FONT_HERSHEY_PLAIN, 2, red, 1, cv.LINE_AA)\n",
    "\n",
    "show_img(img)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53c7ce644e3f6210fe490b2e7844b26f537b2740ab8b6d88e5c764ce633e4d3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
